{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HimanshuPathak2725/googleColab/blob/main/FishClip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym8ZYsl99H5A"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "# df = load_dataset(\"Otolith/FishCLIP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTslqZBF9Wo_"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwpnW-tJ90bJ"
      },
      "outputs": [],
      "source": [
        "# # datasets in colom using pandas\n",
        "# df = df[\"train\"].to_pandas()\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsxOgad9sDaB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJZ97YSmOQKM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w2dmAmUOWx1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images/fishclip.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROmFRhhz_ctZ"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSuwILjxBZW4"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e40eb59c"
      },
      "source": [
        "# Task\n",
        "Download images from the URLs in the \"photo_url\" column of the dataframe and save them locally. Add a new column to the dataframe with the local file paths of the downloaded images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24c6594e"
      },
      "source": [
        "## Create a directory\n",
        "\n",
        "### Subtask:\n",
        "Create a local directory to store the downloaded images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c95eae7"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a directory to store the downloaded images using the `os` module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "197b9f25"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images\"\n",
        "os.makedirs(image_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eaf57bf"
      },
      "source": [
        "## Define a function to download images\n",
        "\n",
        "### Subtask:\n",
        "Create a function that takes a URL and a file path as input, downloads the image from the URL, and saves it to the specified file path.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41b86301"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to download an image from a URL and save it to a specified file path, including error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71464dce"
      },
      "outputs": [],
      "source": [
        "def download_image(url, file_path):\n",
        "    \"\"\"\n",
        "    Downloads an image from a URL and saves it to a file path.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the image.\n",
        "        file_path: The path to save the image.\n",
        "\n",
        "    Returns:\n",
        "        The file_path if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "        with open(file_path, 'wb') as out_file:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                out_file.write(chunk)\n",
        "        return file_path\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download image from {url}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346abfe8"
      },
      "source": [
        "## Apply the function to the dataframe\n",
        "\n",
        "### Subtask:\n",
        "Apply the image downloading function to each row of the DataFrame to download the images and store the local file paths in a new column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "259b6c6a"
      },
      "outputs": [],
      "source": [
        "image_dir = \"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images\"\n",
        "\n",
        "# Add a new column 'local_image_path' with initial None values\n",
        "# df['local_image_path'] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhzqp9CBC3Ag"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HZabNYmART2"
      },
      "outputs": [],
      "source": [
        "# saving the datset in csv format\n",
        "# df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images/fishclip.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfcVTEiXBPL1"
      },
      "outputs": [],
      "source": [
        "# Iterate through the DataFrame and download images if they don't exist locally\n",
        "# for index, row in df.iterrows():\n",
        "#     file_path = os.path.join(image_dir, f\"{row['photo_id']}.jpg\")\n",
        "\n",
        "#     if not os.path.exists(file_path):\n",
        "#         downloaded_path = download_image(row['photo_url'], file_path)\n",
        "\n",
        "#         if downloaded_path:\n",
        "#             df.at[index, 'local_image_path'] = downloaded_path\n",
        "#     else:\n",
        "\n",
        "#         df.at[index, 'local_image_path'] = file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-O7KvLcGmGD"
      },
      "outputs": [],
      "source": [
        "# saving the datset in csv format\n",
        "# df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images/fishclip.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cda9408d"
      },
      "outputs": [],
      "source": [
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFSH6DVUtIMG"
      },
      "outputs": [],
      "source": [
        "#Finding the the number of images in \"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images\"\n",
        "len(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/downloaded_fish_images\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M564eE9tTYY"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vxii-5kEtx_z"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9jWz6W7JbmW"
      },
      "outputs": [],
      "source": [
        "#To find each unique value name in each of the columns\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values in column '{column}':\")\n",
        "    print(unique_values)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLkNx63sKtDx"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRlESZ3aJmJg"
      },
      "outputs": [],
      "source": [
        "#Fine tuning a fathomnet model on the given data for image classification using tensorflow\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8f6cd17"
      },
      "source": [
        "## Prepare Data Generators\n",
        "\n",
        "### Subtask:\n",
        "Create data generators for training and validation using `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aza_PKgSccnE"
      },
      "outputs": [],
      "source": [
        "#droppping the rows with null values\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MoiiJ64cyXY"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7321d644"
      },
      "outputs": [],
      "source": [
        "# Define image dimensions and batch size\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Create ImageDataGenerators for training and validation\n",
        "# Note: Since we're using a pre-trained model, we only need minimal augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Create data generators from the DataFrame\n",
        "# Ensure your DataFrame has 'local_image_path' and 'Species' columns\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col='local_image_path',\n",
        "    y_col='Species',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = valid_datagen.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col='local_image_path',\n",
        "    y_col='Species',\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(f\"Number of classes: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59791c72"
      },
      "source": [
        "## Load and Modify the Pre-trained Model\n",
        "\n",
        "### Subtask:\n",
        "Load the pre-trained EfficientNetB0 model and add a new output layer for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "984d7505"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained EfficientNetB0 model\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Freeze the convolutional base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new layers for classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASjuexCcS_NO"
      },
      "outputs": [],
      "source": [
        "#compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yPKe3dEc9Tt"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "EPOCHS = 10 # You can adjust the number of epochs\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efdf18b8"
      },
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the performance of the trained model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d8e5236"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the validation set\n",
        "loss, accuracy = model.evaluate(validation_generator)\n",
        "\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XgtHhqy0uxc5ojuFBWFg1445KgTMHJ-y",
      "authorship_tag": "ABX9TyO4z3ieUYzVPPJNbncuKAn2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}